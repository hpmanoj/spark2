[WARN] 2018-10-19 00:10:04,591 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] 2018-10-19 00:10:09,962 org.apache.spark.executor.Executor logError - Exception in task 1.0 in stage 0.0 (TID 1)
java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[ERROR] 2018-10-19 00:10:09,962 org.apache.spark.executor.Executor logError - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: ""
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[WARN] 2018-10-19 00:10:10,113 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: ""
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[ERROR] 2018-10-19 00:10:10,128 org.apache.spark.scheduler.TaskSetManager logError - Task 0 in stage 0.0 failed 1 times; aborting job
[WARN] 2018-10-19 00:10:10,159 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[WARN] 2018-10-19 00:12:10,413 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] 2018-10-19 00:12:15,530 org.apache.spark.executor.Executor logError - Exception in task 1.0 in stage 0.0 (TID 1)
java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[ERROR] 2018-10-19 00:12:15,530 org.apache.spark.executor.Executor logError - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: "2	"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[WARN] 2018-10-19 00:12:15,655 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[ERROR] 2018-10-19 00:12:15,686 org.apache.spark.scheduler.TaskSetManager logError - Task 1 in stage 0.0 failed 1 times; aborting job
[WARN] 2018-10-19 00:12:15,723 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: "2	"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[WARN] 2018-10-19 00:13:55,671 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] 2018-10-19 00:14:01,935 org.apache.spark.executor.Executor logError - Exception in task 1.0 in stage 0.0 (TID 1)
java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[ERROR] 2018-10-19 00:14:01,950 org.apache.spark.executor.Executor logError - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: "2	"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[WARN] 2018-10-19 00:14:02,091 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[ERROR] 2018-10-19 00:14:02,091 org.apache.spark.scheduler.TaskSetManager logError - Task 1 in stage 0.0 failed 1 times; aborting job
[WARN] 2018-10-19 00:14:02,143 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: "2	"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[WARN] 2018-10-19 00:14:40,708 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WARN] 2018-10-19 00:16:12,476 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WARN] 2018-10-19 00:16:35,077 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WARN] 2018-10-19 00:18:50,947 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WARN] 2018-10-19 00:34:22,793 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WARN] 2018-10-19 00:38:10,661 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WARN] 2018-10-19 00:39:45,391 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] 2018-10-19 00:39:50,561 org.apache.spark.executor.Executor logError - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: "2	"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[ERROR] 2018-10-19 00:39:50,561 org.apache.spark.executor.Executor logError - Exception in task 1.0 in stage 0.0 (TID 1)
java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[WARN] 2018-10-19 00:39:50,724 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[ERROR] 2018-10-19 00:39:50,771 org.apache.spark.scheduler.TaskSetManager logError - Task 1 in stage 0.0 failed 1 times; aborting job
[WARN] 2018-10-19 00:39:50,816 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: "2	"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[WARN] 2018-10-19 00:42:51,966 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] 2018-10-19 00:42:57,152 org.apache.spark.executor.Executor logError - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: "2	"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[ERROR] 2018-10-19 00:42:57,152 org.apache.spark.executor.Executor logError - Exception in task 1.0 in stage 0.0 (TID 1)
java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[WARN] 2018-10-19 00:42:57,416 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: "2	"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[ERROR] 2018-10-19 00:42:57,490 org.apache.spark.scheduler.TaskSetManager logError - Task 0 in stage 0.0 failed 1 times; aborting job
[WARN] 2018-10-19 00:42:57,567 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[WARN] 2018-10-19 00:45:43,502 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] 2018-10-19 00:45:48,588 org.apache.spark.executor.Executor logError - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: "97	101	103	107	109	113"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[ERROR] 2018-10-19 00:45:48,588 org.apache.spark.executor.Executor logError - Exception in task 1.0 in stage 0.0 (TID 1)
java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[WARN] 2018-10-19 00:45:48,757 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[ERROR] 2018-10-19 00:45:48,772 org.apache.spark.scheduler.TaskSetManager logError - Task 1 in stage 0.0 failed 1 times; aborting job
[WARN] 2018-10-19 00:45:48,803 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: "97	101	103	107	109	113"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:22)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[WARN] 2018-10-19 00:47:48,869 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] 2018-10-19 00:47:54,173 org.apache.spark.executor.Executor logError - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: "97	101	103	107	109	113"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:23)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:23)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[ERROR] 2018-10-19 00:47:54,173 org.apache.spark.executor.Executor logError - Exception in task 1.0 in stage 0.0 (TID 1)
java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:23)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:23)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[WARN] 2018-10-19 00:47:54,347 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:23)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:23)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[ERROR] 2018-10-19 00:47:54,347 org.apache.spark.scheduler.TaskSetManager logError - Task 1 in stage 0.0 failed 1 times; aborting job
[WARN] 2018-10-19 00:47:54,456 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: "97	101	103	107	109	113"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:23)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:23)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[WARN] 2018-10-19 00:49:08,244 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[ERROR] 2018-10-19 00:49:13,403 org.apache.spark.executor.Executor logError - Exception in task 1.0 in stage 0.0 (TID 1)
java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:24)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:24)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[ERROR] 2018-10-19 00:49:13,403 org.apache.spark.executor.Executor logError - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: "97	101	103	107	109	113"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:24)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:24)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[WARN] 2018-10-19 00:49:13,506 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.NumberFormatException: For input string: "283	293	307	311	313	317	331	337	347	349"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:24)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:24)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[ERROR] 2018-10-19 00:49:13,569 org.apache.spark.scheduler.TaskSetManager logError - Task 1 in stage 0.0 failed 1 times; aborting job
[WARN] 2018-10-19 00:49:13,584 org.apache.spark.scheduler.TaskSetManager logWarning - Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): java.lang.NumberFormatException: For input string: "97	101	103	107	109	113"
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at java.lang.Integer.parseInt(Unknown Source)
	at scala.collection.immutable.StringLike$class.toInt(StringLike.scala:273)
	at scala.collection.immutable.StringOps.toInt(StringOps.scala:29)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:24)
	at com.sparkTutorial.rdd.sumOfNumbers.SumOfNumbersProblem$$anonfun$4.apply(SumOfNumbersProblem.scala:24)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:410)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.reduceLeft(TraversableOnce.scala:185)
	at scala.collection.AbstractIterator.reduceLeft(Iterator.scala:1334)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1011)
	at org.apache.spark.rdd.RDD$$anonfun$reduce$1$$anonfun$15.apply(RDD.scala:1009)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:1980)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[WARN] 2018-10-19 00:51:24,856 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WARN] 2018-10-19 01:55:58,954 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WARN] 2018-10-19 01:59:58,168 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WARN] 2018-10-19 02:20:44,019 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WARN] 2018-10-19 02:26:31,725 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WARN] 2018-10-19 02:27:43,653 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WARN] 2018-10-19 16:12:58,727 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WARN] 2018-10-19 16:18:06,473 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WARN] 2018-10-19 16:19:48,175 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[WARN] 2018-10-19 16:22:34,322 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
